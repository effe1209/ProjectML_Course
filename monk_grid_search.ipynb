{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "225a147a",
   "metadata": {},
   "source": [
    "# Monk Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8bb7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from model.network import NeuralNetwork\n",
    "from model.trainer import Trainer\n",
    "from model.losses import Loss\n",
    "from utils import DataLoader\n",
    "from utils import load_monk, plot_curves\n",
    "from utils.model_selection_helpers import count_parameters\n",
    "from model.activations import sigmoid\n",
    "from model.losses import mse\n",
    "from utils.grid_search import grid_search_monk\n",
    "from IPython.display import clear_output\n",
    "\n",
    "np.random.seed(8) #reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d599dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the configurations to test for the training\n",
    "# Neural Network architectures\n",
    "INPUT_NEURONS = 17\n",
    "OUTPUT_NEURONS = 1\n",
    "\n",
    "HIDDEN_LAYER_SIZES = [4, 8]\n",
    "HIDDEN_LAYERS_COUNTS = [1, 2]\n",
    "INTERNAL_ACTIVATIONS = ['tanh', 'leaky relu', 'relu']\n",
    "OUTPUT_ACTIVATIONS_AND_LOSS = [('sigmoid', 'mse'), ('identity', 'binary cross entropy sigmoid')]\n",
    "NEURAL_NETWORK_CONFIGURATIONS = []\n",
    "\n",
    "for hidden_layers_count in HIDDEN_LAYERS_COUNTS:\n",
    "    for hidden_layer_size in HIDDEN_LAYER_SIZES:\n",
    "        for internal_activation in INTERNAL_ACTIVATIONS:\n",
    "            for output_activation, loss_function in OUTPUT_ACTIVATIONS_AND_LOSS:\n",
    "                architecture = [INPUT_NEURONS] + [hidden_layer_size] * hidden_layers_count + [OUTPUT_NEURONS]\n",
    "                activations = [internal_activation] * hidden_layers_count + [output_activation]\n",
    "                NEURAL_NETWORK_CONFIGURATIONS.append((architecture, activations, loss_function))\n",
    "\n",
    "# Training parameters\n",
    "ETA_CONFIGURATIONS = [0.25, 0.1]\n",
    "LAMBDA_CONFIGURATIONS = [0, 1e-1, 1e-2, 1e-3]\n",
    "ALPHA_CONFIGURATIONS = [0, 0.5, 0.9]\n",
    "BATCH_SIZES = [32, -1]\n",
    "\n",
    "# Cross-validation parameters\n",
    "K_FOLDS= 5\n",
    "EPOCHS = 500\n",
    "EARLY_STOPPING_PATIENCE = 50\n",
    "\n",
    "# All possible configurations are tuples (NEURAL_NETWORK_ARCHITECTURE, NEURAL_NETWORK_ACTIVATION, LOSS_F, ETA, LAMBDA, ALPHA, BATCH_SIZE)\n",
    "CONFIGURATIONS = []\n",
    "\n",
    "for NEURAL_NETWORK_ARCHITECTURE, NEURAL_NETWORK_ACTIVATION, LOSS_F in NEURAL_NETWORK_CONFIGURATIONS:\n",
    "  for ETA in ETA_CONFIGURATIONS:\n",
    "    for LAMBDA in LAMBDA_CONFIGURATIONS:\n",
    "      for ALPHA in ALPHA_CONFIGURATIONS:\n",
    "        for BATCH_SIZE in BATCH_SIZES:\n",
    "            config = (NEURAL_NETWORK_ARCHITECTURE, NEURAL_NETWORK_ACTIVATION, LOSS_F, ETA, LAMBDA, ALPHA, BATCH_SIZE)\n",
    "            CONFIGURATIONS.append(config)\n",
    "LEN_CONFIGURATIONS = len(CONFIGURATIONS)\n",
    "\n",
    "print(f\"Total configurations: {LEN_CONFIGURATIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5bdabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG_DICTIONARY is the id of each configuration of CONFIGURATIONS\n",
    "# CONFIG_DICTIONARY_INSTABILITY_VAL is the sumatory of the relative value of when val loss raises\n",
    "# CONFIG_DICTIONARY_INSTABILITY_TRAIN is the sumatory of the relative value of when train loss raises\n",
    "# CONFIG_DICTIONARY_EPOCHS stores the epochs needed for each configuration to train\n",
    "# CONFIG_DICTIONARY_TRAIN_LOSS_DIFF stores the sumatory of when train loss < val loss, so the model is overfitting\n",
    "\n",
    "def print_top_25(CONFIG_DICTIONARY, CONFIG_DICTIONARY_INSTABILITY_VAL, CONFIG_DICTIONARY_INSTABILITY_TRAIN, CONFIG_DICTIONARY_EPOCHS, CONFIG_DICTIONARY_TRAIN_LOSS_DIFF, min_acc = 100):\n",
    "    # print the top 25 configurations, sorting criterias: 1 avg accuracy (no longer valued if > than min_acc), 2 n parameters (the less the better), 3 val instability coeff (the less the better)\n",
    "    TOP_25_CONFIGS_INDEXES = sorted(CONFIG_DICTIONARY, key=lambda i: (-min(min_acc, CONFIG_DICTIONARY[i]), count_parameters(CONFIGURATIONS[i][0]), (CONFIG_DICTIONARY_INSTABILITY_VAL[i]) / K_FOLDS))[:25]\n",
    "    print(\"Top 5 configurations:\")\n",
    "    for i in TOP_25_CONFIGS_INDEXES:\n",
    "        ACCURACY = CONFIG_DICTIONARY[i] * 100 / K_FOLDS\n",
    "        print(f'''Config index: {CONFIGURATIONS[i]}, Mean Accuracy: {ACCURACY}%,\n",
    "            training instability coeff validation: {CONFIG_DICTIONARY_INSTABILITY_VAL[i] / K_FOLDS}, \n",
    "            training instability coeff train: {CONFIG_DICTIONARY_INSTABILITY_TRAIN[i] / K_FOLDS}, \n",
    "            training loss-val loss diff: {CONFIG_DICTIONARY_TRAIN_LOSS_DIFF[i] / K_FOLDS}, \n",
    "            Mean Epochs: {CONFIG_DICTIONARY_EPOCHS[i] // K_FOLDS}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e37d2f1",
   "metadata": {},
   "source": [
    "## Monk 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98155d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we load the dataset and create k folds\n",
    "PATH_TRAIN = 'data/monk/monks-1.train'\n",
    "PATH_TEST = 'data/monk/monks-1.test'\n",
    "X_train_full, y_train_full, X_test, y_test = load_monk(PATH_TRAIN, PATH_TEST)\n",
    "monk_dataset_1 = DataLoader(X_train_full, y_train_full)\n",
    "k_fold = monk_dataset_1.k_fold(k = K_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f81add",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_s_outputs = grid_search_monk(LEN_CONFIGURATIONS, CONFIGURATIONS, k_fold, EPOCHS, EARLY_STOPPING_PATIENCE)\n",
    "clear_output(wait=False)\n",
    "CONFIG_DICTIONARY, CONFIG_DICTIONARY_EPOCHS, CONFIG_DICTIONARY_INSTABILITY_TRAIN, CONFIG_DICTIONARY_INSTABILITY_VAL, CONFIG_DICTIONARY_TRAIN_LOSS_DIFF = grid_s_outputs\n",
    "print_top_25(CONFIG_DICTIONARY, CONFIG_DICTIONARY_INSTABILITY_VAL, CONFIG_DICTIONARY_INSTABILITY_TRAIN, CONFIG_DICTIONARY_EPOCHS, CONFIG_DICTIONARY_TRAIN_LOSS_DIFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0696dbdf",
   "metadata": {},
   "source": [
    "## Monk 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e3e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we load the dataset and create k folds\n",
    "PATH_TRAIN = 'data/monk/monks-2.train'\n",
    "PATH_TEST = 'data/monk/monks-2.test'\n",
    "X_train_full, y_train_full, X_test, y_test = load_monk(PATH_TRAIN, PATH_TEST)\n",
    "monk_dataset_2 = DataLoader(X_train_full, y_train_full)\n",
    "k_fold = monk_dataset_2.k_fold(k = K_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5296144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_s_outputs = grid_search_monk(LEN_CONFIGURATIONS, CONFIGURATIONS, k_fold, EPOCHS = 500, EARLY_STOPPING_PATIENCE = EARLY_STOPPING_PATIENCE)\n",
    "clear_output(wait=False)\n",
    "CONFIG_DICTIONARY, CONFIG_DICTIONARY_EPOCHS, CONFIG_DICTIONARY_INSTABILITY_TRAIN, CONFIG_DICTIONARY_INSTABILITY_VAL, CONFIG_DICTIONARY_TRAIN_LOSS_DIFF = grid_s_outputs\n",
    "print_top_25(CONFIG_DICTIONARY, CONFIG_DICTIONARY_INSTABILITY_VAL, CONFIG_DICTIONARY_INSTABILITY_TRAIN, CONFIG_DICTIONARY_EPOCHS, CONFIG_DICTIONARY_TRAIN_LOSS_DIFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791311d7",
   "metadata": {},
   "source": [
    "## Monk 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we load the dataset and create k folds\n",
    "PATH_TRAIN = 'data/monk/monks-3.train'\n",
    "PATH_TEST = 'data/monk/monks-3.test'\n",
    "X_train_full, y_train_full, X_test, y_test = load_monk(PATH_TRAIN, PATH_TEST)\n",
    "monk_dataset_3 = DataLoader(X_train_full, y_train_full)\n",
    "k_fold = monk_dataset_3.k_fold(k = K_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d91302",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_s_outputs = grid_search_monk(LEN_CONFIGURATIONS, CONFIGURATIONS, k_fold, EPOCHS = 500, EARLY_STOPPING_PATIENCE = EARLY_STOPPING_PATIENCE)\n",
    "clear_output(wait=False)\n",
    "CONFIG_DICTIONARY, CONFIG_DICTIONARY_EPOCHS, CONFIG_DICTIONARY_INSTABILITY_TRAIN, CONFIG_DICTIONARY_INSTABILITY_VAL, CONFIG_DICTIONARY_TRAIN_LOSS_DIFF = grid_s_outputs\n",
    "print_top_25(CONFIG_DICTIONARY, CONFIG_DICTIONARY_INSTABILITY_VAL, CONFIG_DICTIONARY_INSTABILITY_TRAIN, CONFIG_DICTIONARY_EPOCHS, CONFIG_DICTIONARY_TRAIN_LOSS_DIFF, min_acc=93.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c53c9",
   "metadata": {},
   "source": [
    "## Monk 3 no reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets choose an overfitting config here\n",
    "# print the top 25 configurations, sorting criterias: 1 avg accuracy (no longer valued if > than min_acc), 2 n parameters (the less the better), 3 val instability coeff (the less the better)\n",
    "TOP_25_CONFIGS_INDEXES = sorted(CONFIG_DICTIONARY, key=lambda i: (-count_parameters(CONFIGURATIONS[i][0]), -CONFIG_DICTIONARY[i], (CONFIG_DICTIONARY_INSTABILITY_VAL[i]) / K_FOLDS))[:100]\n",
    "print(\"Top 5 configurations:\")\n",
    "for i in TOP_25_CONFIGS_INDEXES:\n",
    "    ACCURACY = CONFIG_DICTIONARY[i] * 100 / K_FOLDS\n",
    "    print(f'''Config index: {CONFIGURATIONS[i]}, Mean Accuracy: {ACCURACY}%,\n",
    "        training instability coeff validation: {CONFIG_DICTIONARY_INSTABILITY_VAL[i] / K_FOLDS}, \n",
    "        training instability coeff train: {CONFIG_DICTIONARY_INSTABILITY_TRAIN[i] / K_FOLDS}, \n",
    "        training loss-val loss diff: {CONFIG_DICTIONARY_TRAIN_LOSS_DIFF[i] / K_FOLDS}, \n",
    "        Mean Epochs: {CONFIG_DICTIONARY_EPOCHS[i] // K_FOLDS}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50843122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
